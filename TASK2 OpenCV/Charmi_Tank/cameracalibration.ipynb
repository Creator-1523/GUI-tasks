{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera Calibrated:  2.4507065100272154\n",
      "\n",
      "camera Matrix:\n",
      "  [[572.63628798   0.         323.85856158]\n",
      " [  0.         726.09268716 232.32032612]\n",
      " [  0.           0.           1.        ]]\n",
      "\n",
      " Distortion parameter:\n",
      "  [[ -7.49011812  31.77672072   0.06404403   0.91656772 -47.67094777]]\n",
      "\n",
      "Rotation Vector:\n",
      "  [array([[-2.26695483],\n",
      "       [-2.3064591 ],\n",
      "       [-0.42707114]]), array([[ 2.36086179],\n",
      "       [ 2.47635362],\n",
      "       [-0.89228764]]), array([[-2.25548404],\n",
      "       [-2.29880993],\n",
      "       [-0.3217645 ]]), array([[-1.89191689],\n",
      "       [-1.95243141],\n",
      "       [ 0.64451502]]), array([[-2.22513286],\n",
      "       [-2.22310273],\n",
      "       [-0.34991158]]), array([[-2.23542267],\n",
      "       [-2.21784768],\n",
      "       [-0.32217699]]), array([[-2.13110628],\n",
      "       [-2.13512332],\n",
      "       [ 0.46994404]]), array([[-2.11567162],\n",
      "       [-2.07245548],\n",
      "       [-0.17989477]]), array([[2.24277458],\n",
      "       [2.21252768],\n",
      "       [0.14666746]]), array([[-2.12200266],\n",
      "       [-2.06836777],\n",
      "       [-0.24842292]])]\n",
      "\n",
      "Translation Vector : \n",
      " [array([[ 624.76265357],\n",
      "       [-230.9970093 ],\n",
      "       [2714.15370527]]), array([[ 601.02298273],\n",
      "       [-242.13158662],\n",
      "       [2820.16998437]]), array([[ 511.11237025],\n",
      "       [-236.51829999],\n",
      "       [2577.79221922]]), array([[ 454.86301967],\n",
      "       [-219.73365312],\n",
      "       [2621.67080975]]), array([[ 324.93024468],\n",
      "       [-189.7720566 ],\n",
      "       [2448.98640327]]), array([[ 276.43105273],\n",
      "       [-181.32443217],\n",
      "       [2478.08883334]]), array([[ 207.92719928],\n",
      "       [-178.56557889],\n",
      "       [2577.45086287]]), array([[ 157.14519204],\n",
      "       [-185.12396006],\n",
      "       [2414.12524844]]), array([[ 146.14726885],\n",
      "       [-192.51186313],\n",
      "       [2454.83065786]]), array([[ 123.20156083],\n",
      "       [-178.46678106],\n",
      "       [2370.04347911]])]\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-451fc8dc882f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DST\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;31m# Reprojection Error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[0mmean_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "#Blob Detector\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "blobParams = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "blobParams.minThreshold = 8\n",
    "blobParams.maxThreshold = 255\n",
    "\n",
    "# Filter by Area.   #provide our landing data\n",
    "blobParams.filterByArea = True\n",
    "blobParams.minArea = 64     # minArea may be adjusted to suit for your experiment\n",
    "blobParams.maxArea = 2500   # maxArea may be adjusted to suit for your experiment\n",
    "\n",
    "# Filter by Circularity\n",
    "blobParams.filterByCircularity = True\n",
    "blobParams.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "blobParams.filterByConvexity = True\n",
    "blobParams.minConvexity = 0.87\n",
    "\n",
    "# Filter by Inertia\n",
    "blobParams.filterByInertia = True\n",
    "blobParams.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "blobDetector = cv2.SimpleBlobDetector_create(blobParams)\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# Original blob coordinates, supposing all blobs are of z-coordinates 0\n",
    "# And, the distance between every two neighbour blob circle centers is 72 centimetres\n",
    "# In fact, any number can be used to replace 72.\n",
    "# Namely, the real size of the circle is pointless while calculating camera calibration parameters.\n",
    "objp = np.zeros((44, 3), np.float32)\n",
    "objp[0]  = (0  , 0  , 0)\n",
    "objp[1]  = (0  , 72 , 0)\n",
    "objp[2]  = (0  , 144, 0)\n",
    "objp[3]  = (0  , 216, 0)\n",
    "objp[4]  = (36 , 36 , 0)\n",
    "objp[5]  = (36 , 108, 0)\n",
    "objp[6]  = (36 , 180, 0)\n",
    "objp[7]  = (36 , 252, 0)\n",
    "objp[8]  = (72 , 0  , 0)\n",
    "objp[9]  = (72 , 72 , 0)\n",
    "objp[10] = (72 , 144, 0)\n",
    "objp[11] = (72 , 216, 0)\n",
    "objp[12] = (108, 36,  0)\n",
    "objp[13] = (108, 108, 0)\n",
    "objp[14] = (108, 180, 0)\n",
    "objp[15] = (108, 252, 0)\n",
    "objp[16] = (144, 0  , 0)\n",
    "objp[17] = (144, 72 , 0)\n",
    "objp[18] = (144, 144, 0)\n",
    "objp[19] = (144, 216, 0)\n",
    "objp[20] = (180, 36 , 0)\n",
    "objp[21] = (180, 108, 0)\n",
    "objp[22] = (180, 180, 0)\n",
    "objp[23] = (180, 252, 0)\n",
    "objp[24] = (216, 0  , 0)\n",
    "objp[25] = (216, 72 , 0)\n",
    "objp[26] = (216, 144, 0)\n",
    "objp[27] = (216, 216, 0)\n",
    "objp[28] = (252, 36 , 0)\n",
    "objp[29] = (252, 108, 0)\n",
    "objp[30] = (252, 180, 0)\n",
    "objp[31] = (252, 252, 0)\n",
    "objp[32] = (288, 0  , 0)\n",
    "objp[33] = (288, 72 , 0)\n",
    "objp[34] = (288, 144, 0)\n",
    "objp[35] = (288, 216, 0)\n",
    "objp[36] = (324, 36 , 0)\n",
    "objp[37] = (324, 108, 0)\n",
    "objp[38] = (324, 180, 0)\n",
    "objp[39] = (324, 252, 0)\n",
    "objp[40] = (360, 0  , 0)\n",
    "objp[41] = (360, 72 , 0)\n",
    "objp[42] = (360, 144, 0)\n",
    "objp[43] = (360, 216, 0)\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "num = 10\n",
    "found = 0\n",
    "while(found < num):  # Here, 10 can be changed to whatever number you like to choose\n",
    "    ret, img = cap.read() # Capture frame-by-frame\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    keypoints = blobDetector.detect(gray) # Detect blobs.\n",
    "\n",
    "    # Draw detected blobs as red circles. This helps cv2.findCirclesGrid() . \n",
    "    im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (0,255,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (4,11), None, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   # Find the circle grid\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)  # Certainly, every loop objp is the same, in 3D.\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (11,11), (-1,-1), criteria)    # Refines the corner locations.\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners.\n",
    "        im_with_keypoints = cv2.drawChessboardCorners(img, (4,11), corners2, ret)\n",
    "\n",
    "        # Enable the following 2 lines if you want to save the calibration images.\n",
    "        # filename = str(found) +\".jpg\"\n",
    "        # cv2.imwrite(filename, im_with_keypoints)\n",
    "\n",
    "        found += 1\n",
    "\n",
    "\n",
    "    cv2.imshow(\"img\", im_with_keypoints) # display\n",
    "    cv2.imshow(\"gray\", gray)\n",
    "    cv2.waitKey(2)\n",
    "\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"camera Calibrated: \",ret)\n",
    "print(\"\\ncamera Matrix:\\n \",mtx)\n",
    "print(\"\\n Distortion parameter:\\n \",dist)\n",
    "print(\"\\nRotation Vector:\\n \",rvecs)\n",
    "print(\"\\nTranslation Vector : \\n\",tvecs)\n",
    "\n",
    "####### UNDISTORTION ############\n",
    "h,w=img.shape[:2]\n",
    "newCameraMatrix, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# Undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newCameraMatrix)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "# cv2.imshow('caliResult1.png', dst)\n",
    "\n",
    "# Undistort with Remapping\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newCameraMatrix, (w,h), 5)\n",
    "dst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imshow(\"DST\",dst)\n",
    "# Reprojection Error\n",
    "mean_error = 0\n",
    "\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Python code to write the image (OpenCV 3.2)\n",
    "fs = cv2.FileStorage('calibration.yml', cv2.FILE_STORAGE_WRITE)\n",
    "fs.write('camera_matrix', mtx)\n",
    "fs.write('dist_coeff', dist)\n",
    "fs.release()\n",
    "\n",
    "\n",
    "\n",
    "# If you want to use PyYAML to read and write yaml files,\n",
    "# try the following part\n",
    "# It's very important to transform the matrix to list.\n",
    "# data = {'camera_matrix': np.asarray(mtx).tolist(), 'dist_coeff': np.asarray(dist).tolist()}\n",
    "# with open(\"calibration.yaml\", \"w\") as f:\n",
    "#     yaml.dump(data, f)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "# # You can use the following 4 lines of code to load the data in file \"calibration.yaml\"\n",
    "# # Read YAML file\n",
    "# with open(calibrationFile, 'r') as stream:\n",
    "#     dictionary = yaml.safe_load(stream)\n",
    "# camera_matrix = dictionary.get(\"camera_matrix\")\n",
    "# dist_coeffs = dictionary.get(\"dist_coeff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
