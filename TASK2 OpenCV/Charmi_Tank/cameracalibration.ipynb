{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard imports\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "\n",
    "\n",
    "# termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "#Blob Detector\n",
    "# Setup SimpleBlobDetector parameters.\n",
    "blobParams = cv2.SimpleBlobDetector_Params()\n",
    "\n",
    "# Change thresholds\n",
    "blobParams.minThreshold = 8\n",
    "blobParams.maxThreshold = 255\n",
    "\n",
    "# Filter by Area.   #provide our landing data\n",
    "blobParams.filterByArea = True\n",
    "blobParams.minArea = 64     # minArea may be adjusted to suit for your experiment\n",
    "blobParams.maxArea = 2500   # maxArea may be adjusted to suit for your experiment\n",
    "\n",
    "# Filter by Circularity\n",
    "blobParams.filterByCircularity = True\n",
    "blobParams.minCircularity = 0.1\n",
    "\n",
    "# Filter by Convexity\n",
    "blobParams.filterByConvexity = True\n",
    "blobParams.minConvexity = 0.87\n",
    "\n",
    "# Filter by Inertia\n",
    "blobParams.filterByInertia = True\n",
    "blobParams.minInertiaRatio = 0.01\n",
    "\n",
    "# Create a detector with the parameters\n",
    "blobDetector = cv2.SimpleBlobDetector_create(blobParams)\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# Original blob coordinates, supposing all blobs are of z-coordinates 0\n",
    "# And, the distance between every two neighbour blob circle centers is 72 centimetres\n",
    "# In fact, any number can be used to replace 72.\n",
    "# Namely, the real size of the circle is pointless while calculating camera calibration parameters.\n",
    "objp = np.zeros((44, 3), np.float32)\n",
    "objp[0]  = (0  , 0  , 0)\n",
    "objp[1]  = (0  , 72 , 0)\n",
    "objp[2]  = (0  , 144, 0)\n",
    "objp[3]  = (0  , 216, 0)\n",
    "objp[4]  = (36 , 36 , 0)\n",
    "objp[5]  = (36 , 108, 0)\n",
    "objp[6]  = (36 , 180, 0)\n",
    "objp[7]  = (36 , 252, 0)\n",
    "objp[8]  = (72 , 0  , 0)\n",
    "objp[9]  = (72 , 72 , 0)\n",
    "objp[10] = (72 , 144, 0)\n",
    "objp[11] = (72 , 216, 0)\n",
    "objp[12] = (108, 36,  0)\n",
    "objp[13] = (108, 108, 0)\n",
    "objp[14] = (108, 180, 0)\n",
    "objp[15] = (108, 252, 0)\n",
    "objp[16] = (144, 0  , 0)\n",
    "objp[17] = (144, 72 , 0)\n",
    "objp[18] = (144, 144, 0)\n",
    "objp[19] = (144, 216, 0)\n",
    "objp[20] = (180, 36 , 0)\n",
    "objp[21] = (180, 108, 0)\n",
    "objp[22] = (180, 180, 0)\n",
    "objp[23] = (180, 252, 0)\n",
    "objp[24] = (216, 0  , 0)\n",
    "objp[25] = (216, 72 , 0)\n",
    "objp[26] = (216, 144, 0)\n",
    "objp[27] = (216, 216, 0)\n",
    "objp[28] = (252, 36 , 0)\n",
    "objp[29] = (252, 108, 0)\n",
    "objp[30] = (252, 180, 0)\n",
    "objp[31] = (252, 252, 0)\n",
    "objp[32] = (288, 0  , 0)\n",
    "objp[33] = (288, 72 , 0)\n",
    "objp[34] = (288, 144, 0)\n",
    "objp[35] = (288, 216, 0)\n",
    "objp[36] = (324, 36 , 0)\n",
    "objp[37] = (324, 108, 0)\n",
    "objp[38] = (324, 180, 0)\n",
    "objp[39] = (324, 252, 0)\n",
    "objp[40] = (360, 0  , 0)\n",
    "objp[41] = (360, 72 , 0)\n",
    "objp[42] = (360, 144, 0)\n",
    "objp[43] = (360, 216, 0)\n",
    "###################################################################################################\n",
    "\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d point in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "num = 10\n",
    "found = 0\n",
    "while(found < num):  # Here, 10 can be changed to whatever number you like to choose\n",
    "    ret, img = cap.read() # Capture frame-by-frame\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    keypoints = blobDetector.detect(gray) # Detect blobs.\n",
    "\n",
    "    # Draw detected blobs as red circles. This helps cv2.findCirclesGrid() . \n",
    "    im_with_keypoints = cv2.drawKeypoints(img, keypoints, np.array([]), (0,255,0), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    im_with_keypoints_gray = cv2.cvtColor(im_with_keypoints, cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findCirclesGrid(im_with_keypoints, (4,11), None, flags = cv2.CALIB_CB_ASYMMETRIC_GRID)   # Find the circle grid\n",
    "\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)  # Certainly, every loop objp is the same, in 3D.\n",
    "\n",
    "        corners2 = cv2.cornerSubPix(im_with_keypoints_gray, corners, (11,11), (-1,-1), criteria)    # Refines the corner locations.\n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners.\n",
    "        im_with_keypoints = cv2.drawChessboardCorners(img, (4,11), corners2, ret)\n",
    "\n",
    "        # Enable the following 2 lines if you want to save the calibration images.\n",
    "        # filename = str(found) +\".jpg\"\n",
    "        # cv2.imwrite(filename, im_with_keypoints)\n",
    "\n",
    "        found += 1\n",
    "\n",
    "\n",
    "    cv2.imshow(\"img\", im_with_keypoints) # display\n",
    "    cv2.imshow(\"gray\", gray)\n",
    "    cv2.waitKey(2)\n",
    "\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"camera Calibrated: \",ret)\n",
    "print(\"\\ncamera Matrix:\\n \",mtx)\n",
    "print(\"\\n Distortion parameter:\\n \",dist)\n",
    "print(\"\\nRotation Vector:\\n \",rvecs)\n",
    "print(\"\\nTranslation Vector : \\n\",tvecs)\n",
    "\n",
    "####### UNDISTORTION ############\n",
    "h,w=img.shape[:2]\n",
    "newCameraMatrix, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "\n",
    "# Undistort\n",
    "dst = cv2.undistort(img, mtx, dist, None, newCameraMatrix)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "# cv2.imshow('caliResult1.png', dst)\n",
    "\n",
    "# Undistort with Remapping\n",
    "mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newCameraMatrix, (w,h), 5)\n",
    "dst = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "\n",
    "# crop the image\n",
    "x, y, w, h = roi\n",
    "dst = dst[y:y+h, x:x+w]\n",
    "cv2.imshow(\"DST\",dst)\n",
    "# Reprojection Error\n",
    "mean_error = 0\n",
    "\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#  Python code to write the image (OpenCV 3.2)\n",
    "fs = cv2.FileStorage('calibration.yml', cv2.FILE_STORAGE_WRITE)\n",
    "fs.write('camera_matrix', mtx)\n",
    "fs.write('dist_coeff', dist)\n",
    "fs.release()\n",
    "\n",
    "\n",
    "\n",
    "# If you want to use PyYAML to read and write yaml files,\n",
    "# try the following part\n",
    "# It's very important to transform the matrix to list.\n",
    "# data = {'camera_matrix': np.asarray(mtx).tolist(), 'dist_coeff': np.asarray(dist).tolist()}\n",
    "# with open(\"calibration.yaml\", \"w\") as f:\n",
    "#     yaml.dump(data, f)\n",
    "    \n",
    "# print(data)\n",
    "\n",
    "# # You can use the following 4 lines of code to load the data in file \"calibration.yaml\"\n",
    "# # Read YAML file\n",
    "# with open(calibrationFile, 'r') as stream:\n",
    "#     dictionary = yaml.safe_load(stream)\n",
    "# camera_matrix = dictionary.get(\"camera_matrix\")\n",
    "# dist_coeffs = dictionary.get(\"dist_coeff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
